<!DOCTYPE html><!--[if lt IE 7]>      <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="Artificial Neural Network library implemented in Python">
        <meta name="viewport" content="width=device-width">
        <title>neupy.layers.activations module &mdash; NeuPy</title>
            <link rel="stylesheet" href="../_static/normalize.css" type="text/css">
            <link rel="stylesheet" href="../_static/sphinx.css" type="text/css">
            <link rel="stylesheet" href="../_static/main.css" type="text/css">
            <link rel="stylesheet" href="../_static/flat.css" type="text/css">
            <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
            <link rel="stylesheet" href="../_static/font-awesome.min.css" type="text/css">
        <link rel="shortcut icon" href="../_static/favicon.ico" /><!-- Load modernizr and JQuery -->
        <script src="../_static/vendor/modernizr-2.6.2.min.js"></script>
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="../_static/vendor/jquery-1.8.2.min.js"><\/script>')</script>
        <script src="../_static/plugins.js"></script>
        <script src="../_static/main.js"></script>
        <link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.html" /><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.5',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script><script type="text/javascript" src="../_static/underscore.js"></script><script type="text/javascript" src="../_static/doctools.js"></script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="../_static/disqus.js"></script><script type="text/javascript" src="../_static/js/google_analytics.js"></script><script type="text/javascript" src="../_static/js/script.js"></script><script type="text/javascript" src="../_static/js/copybutton.js"></script>

    <script type="text/javascript">
        $(document).ready(function () {
            // Scroll to content if on small screen
            if (screen.width < 480)
            {
                $(document).scrollTop(document.getElementsByTagName("article")[0].offsetTop - 44);
            }
        });
    </script>
<style media="screen" type="text/css">
    #fork_me { display: none; }
    #fork_me img { position: fixed; top: 0; right: 0; border: 0; width: 130px; }
    @media only screen and (min-width: 768px) { #fork_me { display: inline; } }

    .docutils { width: 100%; }
    .docutils td { padding: 10px; }
    .section { word-wrap:break-word; }
    .descname { font-weight: bold; }
    .highlight-python + .figure { margin-top: 20px; }
    .dataframe { text-align: center !important; width: 100%; margin: 10px 0 10px 0; }
    .dataframe td { padding: 5px; }

    .math .gd { color: #000 !important; } /* Generic.Deleted */
    .math .m { color: #000 !important; } /* Literal.Number */
    .math .s { color: #000 !important; } /* Literal.String */
    .math .mf { color: #000 !important; } /* Literal.Number.Float */
    .math .mh { color: #000 !important; } /* Literal.Number.Hex */
    .math .mi { color: #000 !important; } /* Literal.Number.Integer */
    .math .mo { color: #000 !important; } /* Literal.Number.Oct */
    .math .sc { color: #000 !important; } /* Literal.String.Char */
    .math .s2 { color: #000 !important; } /* Literal.String.Double */
    .math .si { color: #000 !important; } /* Literal.String.Interpol */
    .math .sx { color: #000 !important; } /* Literal.String.Other */
    .math .s1 { color: #000 !important; } /* Literal.String.Single */
    .math .ss { color: #000 !important; } /* Literal.String.Symbol */
    .math .il { color: #000 !important; } /* Literal.Number.Integer.Long */
</style></head>
    <body role="document">
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

      <div id="container"><header role="banner">
            <hgroup>
              <h1><a href="../pages/home.html">NeuPy</a></h1><h2>Neural Networks in Python</h2></hgroup>
          </header>
      <nav role="navigation">
            <ul><li class="main-nav">
                  <a href="../pages/home.html">Home</a>
                </li>
              <li class="main-nav">
                  <a href="../page1.html">Articles</a>
                </li>
              <li class="main-nav">
                  <a href="../pages/documentation.html">Documentation</a>
                </li>
              <li class="main-nav">
                  <a href="../pages/installation.html">Installation</a>
                </li>
              </ul>
          </nav><div class="main-container" role="main"><div class="main wrapper body clearfix"><article>
    <div class="section" id="module-neupy.layers.activations">
<span id="neupy-layers-activations-module"></span><h1>neupy.layers.activations module</h1>
<dl class="class">
<dt id="neupy.layers.activations.ActivationLayer">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">ActivationLayer</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="neupy.layers.base.html#neupy.layers.base.ParameterBasedLayer" title="neupy.layers.base.ParameterBasedLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.base.ParameterBasedLayer</span></span></a></p>
<p>Base class for the layers based on the activation
functions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.ActivationLayer.initialize">
<span class="descname">initialize</span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.ActivationLayer.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neupy.layers.activations.ActivationLayer.output">
<span class="descname">output</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.ActivationLayer.output_shape">
<span class="descname">output_shape</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.Linear">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">Linear</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the linear activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.Linear.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Linear.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.Sigmoid">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">Sigmoid</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the sigmoid activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.Sigmoid.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Sigmoid.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.HardSigmoid">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">HardSigmoid</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the hard sigmoid activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.HardSigmoid.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.HardSigmoid.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.Step">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">Step</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the the step activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.Step.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Step.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.Tanh">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">Tanh</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the <cite>tanh</cite> activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.Tanh.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Tanh.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.Relu">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">Relu</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the rectifier (ReLu) activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>alpha</strong> : float</p>
<blockquote>
<div><p>Alpha parameter defines the decreasing rate
for the negative values. If <span class="docutils literal"><span class="pre">alpha</span></span>
is non-zero value then layer behave like a
leaky ReLu. Defaults to <span class="docutils literal"><span class="pre">0</span></span>.</p>
</div></blockquote>
<p><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.Relu.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Relu.alpha">
<span class="descname">alpha</span><em class="property"> = None</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Relu.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'alpha': Option(class_name='Relu', value=0), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.Softplus">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">Softplus</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the softplus activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.Softplus.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Softplus.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.Softmax">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">Softmax</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the softmax activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.Softmax.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Softmax.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.Elu">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">Elu</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the exponensial linear unit (ELU)
activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>alpha</strong> : float</p>
<blockquote>
<div><p>Alpha parameter defines the decreasing exponensial
rate for the negative values. Defaults to <span class="docutils literal"><span class="pre">1</span></span>.</p>
</div></blockquote>
<p><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[R4]</a></td><td><a class="reference external" href="http://arxiv.org/pdf/1511.07289v3.pdf">http://arxiv.org/pdf/1511.07289v3.pdf</a></td></tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.Elu.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Elu.alpha">
<span class="descname">alpha</span><em class="property"> = None</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.Elu.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'alpha': Option(class_name='Elu', value=1), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neupy.layers.activations.PRelu">
<em class="property">class </em><span class="descclassname">neupy.layers.activations.</span><span class="descname">PRelu</span><span class="sig-paren">(</span><em>size=None</em>, <em>**options</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="#neupy.layers.activations.ActivationLayer" title="neupy.layers.activations.ActivationLayer"><span class="xref py py-class docutils literal"><span class="pre">neupy.layers.activations.ActivationLayer</span></span></a></p>
<p>The layer with the parametrized ReLu activation
function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>alpha_axes</strong> : int or tuple</p>
<blockquote>
<div><p>Axes that will not include unique alpha parameter.
Single integer value defines the same as a tuple with one value.
Defaults to <span class="docutils literal"><span class="pre">1</span></span>.</p>
</div></blockquote>
<p><strong>alpha</strong> : array-like, Theano shared variable, scalar or None</p>
<blockquote>
<div><p>Alpha parameter per each non-shared axis for the ReLu.
Scalar value means that each element in the tensor will be
equal to the specified value.
<span class="docutils literal"><span class="pre">None</span></span> means that parameters will be generated randomly.
The exact random initialization algorithm depends on
the <span class="docutils literal"><span class="pre">init_method</span></span> parameter.
Defaults to <span class="docutils literal"><span class="pre">0.25</span></span>.</p>
</div></blockquote>
<p><strong>size</strong> : int or None</p>
<blockquote>
<div><p>Layer input size. <span class="docutils literal"><span class="pre">None</span></span> means that layer will not create
parameters and will return only activation function
output for the specified input value.</p>
</div></blockquote>
<p><strong>weight</strong> : 2D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer weights. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.
<span class="docutils literal"><span class="pre">None</span></span> by default.</p>
</div></blockquote>
<p><strong>bias</strong> : 1D array-like, Theano shared variable or None</p>
<blockquote>
<div><p>Define your layer bias. <span class="docutils literal"><span class="pre">None</span></span> means that your weights will be
generate randomly dependence on property <span class="docutils literal"><span class="pre">init_method</span></span>.</p>
</div></blockquote>
<p><strong>init_method</strong> : {&#8216;bounded&#8217;, &#8216;normal&#8217;, &#8216;ortho&#8217;, &#8216;xavier_normal&#8217;,    &#8216;xavier_uniform&#8217;, &#8216;he_normal&#8217;, &#8216;he_uniform&#8217;}</p>
<blockquote>
<div><p>Weight initialization method. Defaults to <span class="docutils literal"><span class="pre">xavier_normal</span></span>.</p>
<ul class="simple">
<li><span class="docutils literal"><span class="pre">normal</span></span> will generate random weights from normal distribution         with standard deviation equal to <span class="docutils literal"><span class="pre">0.01</span></span>.</li>
<li><span class="docutils literal"><span class="pre">bounded</span></span> generate random weights from Uniform distribution.</li>
<li><span class="docutils literal"><span class="pre">ortho</span></span> generate random orthogonal matrix.</li>
<li><span class="docutils literal"><span class="pre">xavier_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in} +         fan_{out}}\)</span>. Where <span class="math">\(fan_{in}\)</span> is a number of         layer input units and <span class="math">\(fan_{out}\)</span> - number of layer         output units.</li>
<li><span class="docutils literal"><span class="pre">xavier_uniform</span></span> generate random matrix from uniform         distribution where <span class="math">\(w_{ij} \in         [-\sqrt{\frac{6}{fan_{in} + fan_{out}}},         \sqrt{\frac{6}{fan_{in} + fan_{out}}}\)</span>].</li>
<li><span class="docutils literal"><span class="pre">he_normal</span></span> generate random matrix from normal distrubtion         where variance equal to <span class="math">\(\frac{2}{fan_{in}}\)</span>.         Where <span class="math">\(fan_{in}\)</span> is a number of layer input units.</li>
<li><span class="docutils literal"><span class="pre">he_uniform</span></span> generate random matrix from uniformal         distribution where <span class="math">\(w_{ij} \in [        -\sqrt{\frac{6}{fan_{in}}},         \sqrt{\frac{6}{fan_{in}}}]\)</span></li>
</ul>
</div></blockquote>
<p><strong>bounds</strong> : tuple of two float</p>
<blockquote class="last">
<div><p>Available only for <span class="docutils literal"><span class="pre">init_method</span></span> equal to <span class="docutils literal"><span class="pre">bounded</span></span>.  Value
identify minimum and maximum possible value in random weights.
Defaults to <span class="docutils literal"><span class="pre">(0,</span> <span class="pre">1)</span></span>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[R5]</a></td><td><a class="reference external" href="https://arxiv.org/pdf/1502.01852v1.pdf">https://arxiv.org/pdf/1502.01852v1.pdf</a></td></tr>
</tbody>
</table>
<dl class="method">
<dt id="neupy.layers.activations.PRelu.activation_function">
<span class="descname">activation_function</span><span class="sig-paren">(</span><em>input_value</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.PRelu.alpha">
<span class="descname">alpha</span><em class="property"> = None</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.PRelu.alpha_axes">
<span class="descname">alpha_axes</span><em class="property"> = None</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neupy.layers.activations.PRelu.initialize">
<span class="descname">initialize</span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neupy.layers.activations.PRelu.options">
<span class="descname">options</span><em class="property"> = {'bounds': Option(class_name='ParameterBasedLayer', value=[0, 1]), 'bias': Option(class_name='ParameterBasedLayer', value=None), 'alpha': Option(class_name='PRelu', value=0.25), 'alpha_axes': Option(class_name='PRelu', value=1), 'weight': Option(class_name='ParameterBasedLayer', value=None), 'init_method': Option(class_name='ParameterBasedLayer', value=xavier_normal), 'size': Option(class_name='ParameterBasedLayer', value=None)}</em><a class="reference external" href="https://github.com/itdxer/neupy/tree/master/neupy/layers/activations.py"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

</div>

    <div class="postmeta">
        
        
        
        </div></article><aside class="sidebar"><section><div class="widget">
    <h1>Recent Posts</h1>
    <ul><li>
            <a href="../2015/09/21/password_recovery.html">Password recovery</a>
        </li><li>
            <a href="../2015/09/20/discrete_hopfield_network.html">Discrete Hopfiel Network</a>
        </li><li>
            <a href="../2015/07/04/boston_house_prices_dataset.html">Boston house-prices dataset</a>
        </li><li>
            <a href="../2015/07/04/visualize_backpropagation_algorithms.html">Visualize Algorithms based on the Backpropagation</a>
        </li></ul>
</div>
</section><section><div class="widget">
    <h1>Cheat sheet</h1>
    <ul>
        <li><a href="../docs/algorithms.html#algorithms">Algorithms</a></li>
        <li><a href="../docs/algorithms.html#layers">Layers</a></li>
        <li><a href="../docs/algorithms.html#error-functions">Error functions</a></li>
    </ul>
</div></section><section><div class="widget">
    <h1>Installation</h1>
    <div class="highligh-bash">
        <div class="highlight">
            <pre>pip install neupy</pre>
        </div>
    </div>
    <p>Read more in <a href="../pages/documentation.html">Documentation</a>.</p>
    <p>Old documentations you can find <a href="../pages/versions.html">here</a>.</p>
</div></section><section><div class="widget" id="searchbox" role="search">
    <h1><a href="#searchbox">Search</a></h1>
    <form action="../search.html" method="get">
        <input type="text" name="q" />
        <button type="submit"><span class="fa fa-search"></span></button>
    </form>
</div></section></aside></div> <!-- #main --></div> <!-- #main-container -->

        <div class="footer-container" role="contentinfo"><footer class="wrapper">&copy; Copyright 2015 - 2016, Yurii Shevchuk. Powered by <a href="http://www.tinkerer.me/">Tinkerer</a> and <a href="http://sphinx.pocoo.org/">Sphinx</a>.</footer>
    <a id="fork_me" href="http://github.com/itdxer/neupy">
        <img alt="Fork me" src="../_static/img/github-fork-green.png" />
    </a></div> <!-- footer-container -->

      </div> <!--! end of #container --><script type="text/javascript">    var disqus_shortname = "neupy";    disqus_count();</script><!--[if lt IE 7 ]>
          <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.3/CFInstall.min.js"></script>
          <script>window.attachEvent('onload',function(){CFInstall.check({mode:'overlay'})})</script>
        <![endif]-->
    </body>
</html>